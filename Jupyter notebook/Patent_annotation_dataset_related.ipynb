{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patent annotation:  A novel dataset to highlight patent passages\n",
    "\n",
    "#### Types of data samples\n",
    "\n",
    "- *neutral_samples*: Here the paragraphs just above 'Advantageous Effects of Invention' are collected. \n",
    "   To have a nearly uniformed sequence lengths, only 3 paragraphs are collected. \n",
    "\n",
    "- *positive_samples*: All paragraphs from section/heading 'Advantageous Effects of Invention'\n",
    "\tare collected.\n",
    "\n",
    "- *negative samples*: Paragraphs under the section 'Technical Problem' are collected. \n",
    "\n",
    "\n",
    "- Some of the examples patents containing interested tags as mentioned above are: (just for reference)\n",
    "- You can open Google patents in advanced mode and search for below patents and look for above tags. \n",
    "    - US10842211B2\n",
    "    - US10842310B2\n",
    "    - US10842344B2 \n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the statistics\n",
    "\n",
    "Raw data can be downloaded from: https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/2020/ \n",
    "\n",
    "1. Traverse USPTO bulk data files directory. \n",
    "2. Each xml file contains patents (nearly 8k) granted per week. Essentially, there are 52 such xml files per every year. Each such xml file is a nested file, such that it contains nearly 8k patents and each patent is embedded in xml file.\n",
    "3. Per each week, find the total number of patents and total number of pos/neg/neutral samples found and write these statistics to a csv file. \n",
    "\n",
    "#### For instance:\n",
    "\n",
    "- Year 2020 contains week_1.xml, week_2.xml, ...week_52.xml (total 52 xml files)\n",
    "- week_1.xml is nested file, means to say, it further contains 8k .xml files, each one for a patent. \n",
    "\n",
    "#### Download the files from USPTO:\n",
    "- use this url: https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/2020/ \n",
    "- save it to a directory, for instance: \"/home/renuk/Documents/USPTO_BULK_DATA/patents/2020/\"\n",
    "- Now you can execute the below codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(filename):\n",
    "    #home_dir = \"/home/renuk/Documents/USPTO_BULK_DATA/patents/2020/\"\n",
    "    #file_path =home_dir+filename\n",
    "    \n",
    "    total_neutral_samples = 0 #total_positive_samples , total_negative_samples, total_neutral_samples\n",
    "    total_publications = 0\n",
    "    xml_text = html.unescape(open(filename, 'r').read())\n",
    "    weekly_filename = filename.split('/')\n",
    "    weekly_filename = weekly_filename[-1]\n",
    "    print(weekly_filename)\n",
    "    for patent in xml_text.split(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\"):\n",
    "\n",
    "        if patent is None or patent == \"\":\n",
    "            continue\n",
    "        patent_text = patent\n",
    "    \n",
    "        bs = BeautifulSoup(patent, \"lxml\")\n",
    "            \n",
    "                #try:\n",
    "                \n",
    "        fwu_neutral = bs.find('heading',text='Solution to Problem') #fwu_advantages, fwu_problems, fwu_neutral\n",
    "    \n",
    "        #Advantageous Effects of Invention --- for positive samples\n",
    "        #Technical Problem --- for negative samples\n",
    "        #Solution to Problem --- for neutral samples, also the paragraphs (2/3) which are just above the 'Advantageous Effects of Invention' section can be used for neural samples \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##### search for application or grant\n",
    "        application = bs.find('us-patent-application')\n",
    "        if application is None: # If no application, search for grant\n",
    "            application = bs.find('us-patent-grant')\n",
    "        \n",
    "        title = \"None\"\n",
    "            \n",
    "    #### Search for its title\n",
    "            \n",
    "        try:\n",
    "            title = application.find('invention-title').text\n",
    "        except Exception as e:          \n",
    "            #print(\"no title found\")\n",
    "            title = \"\"\n",
    "                \n",
    "        #print(\"patent is:\", title)\n",
    "            \n",
    "            \n",
    "    #### Search for publication number\n",
    "        try:\n",
    "            #publication_country = application.find('publication-reference').find('country').text\n",
    "            #publication_doc_number = application.find('publication-reference').find('doc-number').text\n",
    "            publication_kind = application.find('publication-reference').find('kind').text\n",
    "            #publication_num = publication_country+publication_doc_number+publication_kind\n",
    "        except Exception as e:\n",
    "            #publication_num = \"\"\n",
    "            publication_kind = \"\"\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            publication_num = application['file'].split(\"-\")[0]\n",
    "        \n",
    "        except Exception as e:\n",
    "            publication_num = \"\"\n",
    "        \n",
    "        \n",
    "        publication_num = publication_num+publication_kind\n",
    "        #print(publication_num)  \n",
    "    \n",
    "        try:\n",
    "            application_type = application.find('application-reference')['appl-type']\n",
    "        \n",
    "        except Exception as e:\n",
    "            application_type =''\n",
    "        #print(application_type)\n",
    "            \n",
    "        if publication_num:\n",
    "            total_publications +=1\n",
    "\n",
    "        if fwu_neutral:  #fwu_advantages, fwu_problems, fwu_neutral\n",
    "            total_neutral_samples +=1\n",
    "        \n",
    "    \n",
    " \n",
    "    return weekly_filename, total_publications, total_neutral_samples\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import html\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "path = \"/home/renuk/Documents/USPTO_BULK_DATA/patents/2020/\" #directory containing weekly xml files (i.e., 52 files per year)\n",
    "all_files = glob.glob(os.path.join(path, \"ipg*.xml\"))\n",
    "df = pd.DataFrame(columns=['weekly_filename', 'total_publications', 'total_neutral_samples'])\n",
    "for filename in all_files:\n",
    "    weekly_filename, total_publications, total_neutral_samples = stats(filename)\n",
    "    df = df.append({'weekly_filename':weekly_filename, 'total_publications': total_publications,\n",
    "                                'total_neutral_samples':total_neutral_samples},ignore_index=True)\n",
    "df.to_csv(\"/home/renuk/Documents/USPTO_BULK_DATA/patents/2020_neutral_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traverse 52 xml files and access postive, negative and neutral samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the following \n",
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import html\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "- change the name of 4th coloumn according to your sample of interest. For instance: 'positive_text' for +ve label.\n",
    "- change tags also accordingly. For instance: fwu_advantages = bs.find('heading',text='Advantageous Effects of Invention') for +ve labels\n",
    "- go through each line of code and change the variable name wherever necessary.\n",
    "- Below code traverse each weekly xml file, find the labels, if found then it will collect the pargarphs from that particular section or tag. \n",
    "- For every weekly xml, there is seperate csv file is stored with data automatically. For instance: '/home/renuk/Documents/USPTO_BULK_DATA/patents/2020/ipg200211.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_data(filename):\n",
    "    #home_dir = \"/home/renuk/Documents/USPTO_BULK_DATA/patents/2020/\"\n",
    "    #file_path =home_dir+filename\n",
    "    df = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', \n",
    "                           'positive_text'])\n",
    "    total_positive_samples = 0\n",
    "    total_publications = 0\n",
    "    xml_text = html.unescape(open(filename, 'r').read())\n",
    "    for patent in xml_text.split(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\"):\n",
    "\n",
    "        if patent is None or patent == \"\":\n",
    "            continue\n",
    "        patent_text = patent\n",
    "    \n",
    "        bs = BeautifulSoup(patent, \"lxml\")\n",
    "            \n",
    "                #try:\n",
    "                \n",
    "        fwu_advantages = bs.find('heading',text='Advantageous Effects of Invention')\n",
    "    \n",
    "                #except Exception as e:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##### search for application or grant\n",
    "        application = bs.find('us-patent-application')\n",
    "        if application is None: # If no application, search for grant\n",
    "            application = bs.find('us-patent-grant')\n",
    "        \n",
    "        title = \"None\"\n",
    "            \n",
    "    #### Search for its title\n",
    "            \n",
    "        try:\n",
    "            title = application.find('invention-title').text\n",
    "        except Exception as e:          \n",
    "            #print(\"no title found\")\n",
    "            title = \"\"\n",
    "                \n",
    "        #print(\"patent is:\", title)\n",
    "            \n",
    "            \n",
    "    #### Search for publication number\n",
    "        try:\n",
    "            #publication_country = application.find('publication-reference').find('country').text\n",
    "            #publication_doc_number = application.find('publication-reference').find('doc-number').text\n",
    "            publication_kind = application.find('publication-reference').find('kind').text\n",
    "            #publication_num = publication_country+publication_doc_number+publication_kind\n",
    "        except Exception as e:\n",
    "            #publication_num = \"\"\n",
    "            publication_kind = \"\"\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            publication_num = application['file'].split(\"-\")[0]\n",
    "        \n",
    "        except Exception as e:\n",
    "            publication_num = \"\"\n",
    "        \n",
    "        \n",
    "        publication_num = publication_num+publication_kind\n",
    "        #print(publication_num)  \n",
    "    \n",
    "        try:\n",
    "            application_type = application.find('application-reference')['appl-type']\n",
    "        \n",
    "        except Exception as e:\n",
    "            application_type =''\n",
    "        #print(application_type)\n",
    "            \n",
    "        if publication_num:\n",
    "            total_publications +=1\n",
    "\n",
    "        if fwu_advantages:\n",
    "            total_positive_samples +=1\n",
    "        \n",
    "            text = patent_text.splitlines()\n",
    "            adv = []\n",
    "            pos_text=\"\"\n",
    "            for i in text:\n",
    "                #print(type(i))\n",
    "                \n",
    "                start = text.index(i)\n",
    "                iteration = 1\n",
    "                if ('>Advantageous Effects of Invention<'in i and iteration==1):\n",
    "                    for j in range(20):\n",
    "                        if '<p' in text[start+1]:\n",
    "                            pos_text = text[start+1]\n",
    "                            #print(pos_text)\n",
    "                            adv.append(text[start+1])\n",
    "                            start = start+1\n",
    "                        else:\n",
    "                            continue\n",
    "                        \n",
    "                    #print(\"patent is:\", title)\n",
    "                    #print(publication_num)\n",
    "                    #print(application_type)\n",
    "                    #print('-----------')\n",
    "                    df = df.append({'publication_number':publication_num, 'patent_title': title,\n",
    "                                'appl_type':application_type,\n",
    "                               'positive_text':adv},ignore_index=True)\n",
    "                \n",
    "                    iteration=0\n",
    "                \n",
    "        #print('-----------')\n",
    "        \n",
    "        \n",
    "        #else:\n",
    "            #total_not_found +=1\n",
    "        \n",
    "    file = filename\n",
    "    name = file.split('.')\n",
    "    name =name[0]+'.csv'\n",
    "    #name = name[-1].split('.')[0]    \n",
    "    \n",
    "    df.to_csv(name)  # for each week, there will be a seperate csv file created and later you can merge them\n",
    "    print('total publications in',filename,total_publications )\n",
    "    print('total positive samples in ', filename,total_positive_samples )\n",
    "    df.shape\n",
    "    print(\"------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_xml_data from here.\n",
    "\n",
    "path = \"/home/renuk/Documents/USPTO_BULK_DATA/patents/2020/\"\n",
    "all_files = glob.glob(os.path.join(path, \"ipg*.xml\"))\n",
    "for filename in all_files:\n",
    "    get_xml_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
