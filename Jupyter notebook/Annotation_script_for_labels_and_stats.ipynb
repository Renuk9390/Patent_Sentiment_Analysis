{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "annotation_script_for_labels_and_stats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gBogXEz0jgR"
      },
      "source": [
        "import os, glob\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "\n",
        "import pprint\n",
        "import os\n",
        "import sys\n",
        "import html\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from datetime import datetime"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCyFgIVz0lrV"
      },
      "source": [
        "def get_xml_data(filename):\n",
        "\n",
        "    home_dir = \"/content/drive/MyDrive/dataset_patent/2019\"\n",
        "    file_path =home_dir+filename\n",
        "\n",
        "   \n",
        "    df_pos = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', \n",
        "                           'positive_text'])  # positive_text,   \n",
        "    df_neg = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', \n",
        "                           'negative_text']) # negative_text\n",
        "    df_neut = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', \n",
        "                           'neutral_text'])  # neutral_text \n",
        "   \n",
        "    total_positive_samples = 0\n",
        "    total_negative_samples = 0\n",
        "    total_neutral_samples = 0\n",
        "\n",
        "    total_publications = 0\n",
        "    xml_text = html.unescape(open(filename, 'r').read())\n",
        "    for patent in xml_text.split(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\"):\n",
        "\n",
        "        if patent is None or patent == \"\":\n",
        "            continue\n",
        "        patent_text = patent\n",
        "    \n",
        "        bs = BeautifulSoup(patent, \"lxml\")\n",
        "\n",
        "        fwu_advantages = bs.find('heading',text='Advantageous Effects of Invention')\n",
        "        fwu_disadvantages = bs.find('heading',text='Technical Problem')\n",
        "        fwu_solutions = bs.find('heading',text='Solution to Problem')\n",
        "\n",
        "        #Advantageous Effects of Invention --- for positive samples\n",
        "        #Technical Problem --- for negative samples\n",
        "        #Solution to Problem --- for neutral samples, also the paragraphs (2/3) which are just above the 'Advantageous Effects of Invention' section can be used for neural samples \n",
        "\n",
        "    #### Search for application or grant\n",
        "        application = bs.find('us-patent-application')\n",
        "        if application is None: # If no application, search for grant\n",
        "            application = bs.find('us-patent-grant')\n",
        "        \n",
        "        title = \"None\"\n",
        "            \n",
        "    #### Search for its title\n",
        "        try:\n",
        "            title = application.find('invention-title').text\n",
        "        except Exception as e:          \n",
        "            #print(\"no title found\")\n",
        "            title = \"\"\n",
        "\n",
        "    #### Search for publication number\n",
        "        try:\n",
        "            publication_kind = application.find('publication-reference').find('kind').text\n",
        "        except Exception as e:\n",
        "            publication_kind = \"\"\n",
        "        \n",
        "        try:\n",
        "            publication_num = application['file'].split(\"-\")[0]\n",
        "        except Exception as e:\n",
        "            publication_num = \"\"\n",
        "        \n",
        "        publication_num = publication_num+publication_kind\n",
        "    \n",
        "        try:\n",
        "            application_type = application.find('application-reference')['appl-type']\n",
        "        \n",
        "        except Exception as e:\n",
        "            application_type =''\n",
        "            \n",
        "        if publication_num:\n",
        "            total_publications +=1\n",
        "\n",
        "#### For positive labels \n",
        "\n",
        "        if fwu_advantages:\n",
        "            total_positive_samples +=1\n",
        "        \n",
        "            text = patent_text.splitlines()\n",
        "            adv = []\n",
        "            pos_text=\"\"\n",
        "\n",
        "            for i in text:\n",
        "                start = text.index(i)\n",
        "                iteration = 1\n",
        "                if ('>Advantageous Effects of Invention<'in i and iteration==1):\n",
        "                    for j in range(20):\n",
        "                        if '<p' in text[start+1]:\n",
        "                            pos_text = text[start+1]\n",
        "                            adv.append(text[start+1])\n",
        "                            start = start+1\n",
        "                        else:\n",
        "                            continue\n",
        "                    df_pos = df_pos.append({'publication_number':publication_num, 'patent_title': title,\n",
        "                                'appl_type':application_type,\n",
        "                               'positive_text':adv},ignore_index=True)\n",
        "                \n",
        "                    iteration=0\n",
        "\n",
        "#### For negative labels\n",
        "      \n",
        "        if fwu_disadvantages:\n",
        "            total_negative_samples +=1\n",
        "        \n",
        "            text = patent_text.splitlines()\n",
        "            disadv = []\n",
        "            neg_text=\"\"\n",
        "\n",
        "            for i in text:\n",
        "                start = text.index(i)\n",
        "                iteration = 1\n",
        "                if ('>Technical Problem<'in i and iteration==1):\n",
        "                    for j in range(20):\n",
        "                        if '<p' in text[start+1]:\n",
        "                            neg_text = text[start+1]\n",
        "                            disadv.append(text[start+1])\n",
        "                            start = start+1\n",
        "                        else:\n",
        "                            continue\n",
        "                    df_neg = df_neg.append({'publication_number':publication_num, 'patent_title': title,\n",
        "                                'appl_type':application_type,\n",
        "                               'negative_text':disadv},ignore_index=True)\n",
        "                \n",
        "                    iteration=0\n",
        "      \n",
        "#### For neutral labels \n",
        "\n",
        "        if fwu_solutions:\n",
        "            total_neutral_samples +=1\n",
        "        \n",
        "            text = patent_text.splitlines()\n",
        "            neut = []\n",
        "            neut_text=\"\"\n",
        "\n",
        "            for i in text:\n",
        "                start = text.index(i)\n",
        "                iteration = 1\n",
        "                if ('>Solution to Problem<'in i and iteration==1):\n",
        "                    for j in range(20):\n",
        "                        if '<p' in text[start+1]:\n",
        "                            neut_text = text[start+1]\n",
        "                            neut.append(text[start+1])\n",
        "                            start = start+1\n",
        "                        else:\n",
        "                            continue\n",
        "                    df_neut = df_neut.append({'publication_number':publication_num, 'patent_title': title,\n",
        "                                'appl_type':application_type,\n",
        "                               'neutral_text':neut},ignore_index=True)\n",
        "                \n",
        "                    iteration=0                                 \n",
        "\n",
        "        \n",
        "    file = filename\n",
        "    name = file.split('.')\n",
        "    name_pos =name[0]+'_pos.csv'\n",
        "    name_neg =name[0]+'_neg.csv'\n",
        "    name_neut =name[0]+'_neut.csv'\n",
        "  \n",
        "    df_pos.to_csv(name_pos)  # for each week, there will be a seperate csv file created and later you can merge them\n",
        "    df_neg.to_csv(name_neg)\n",
        "    df_neut.to_csv(name_neut)\n",
        "\n",
        "    print('total publications in',filename,total_publications )\n",
        "    print('total positive samples in ', filename,total_positive_samples )\n",
        "    print('total publications in',filename,total_publications )\n",
        "    print('total negative samples in ', filename,total_negative_samples )\n",
        "    print('total publications in',filename,total_publications )\n",
        "    print('total neutral samples in ', filename,total_neutral_samples )\n",
        "\n",
        "    \n",
        "    print(df_pos.shape)\n",
        "    print(\"------------\")\n",
        "    print(df_neg.shape)\n",
        "    print(\"------------\")\n",
        "    print(df_neut.shape)\n",
        "    print(\"------------\")\n",
        "\n",
        "    return filename, total_publications, total_positive_samples, total_negative_samples, total_neutral_samples, df_pos, df_neg, df_neut   "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvNP-3w-eSyp"
      },
      "source": [
        "df_stats_pos = pd.DataFrame(columns=['filename', 'total_publications', 'total_positive_samples'])\n",
        "df_stats_neg = pd.DataFrame(columns=['filename', 'total_publications', 'total_negative_samples'])\n",
        "df_stats_neut = pd.DataFrame(columns=['filename', 'total_publications', 'total_neutral_samples'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlBXWW2JvXBW"
      },
      "source": [
        "df_apps_pos = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', 'positive_text'])\n",
        "df_apps_neg = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', 'negative_text'])\n",
        "df_apps_neut = pd.DataFrame(columns=['publication_number', 'patent_title', 'appl_type', 'neutral_text'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QNvFAFQwi1H"
      },
      "source": [
        "start = datetime.now()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JpvA3iE0xJz",
        "outputId": "9d484e7b-9525-4b94-b24d-9fd5876d0896"
      },
      "source": [
        "path = \"/content/drive/MyDrive/dataset_patent/2019\"\n",
        "all_files = glob.glob(os.path.join(path, \"ipg*.xml\"))\n",
        "for filename in all_files:\n",
        "    result = get_xml_data(filename)\n",
        "    df_stats_pos = df_stats_pos.append({'filename':result[0][-13:-4], 'total_publications':result[1], 'total_positive_samples': result[2]},ignore_index=True)\n",
        "    df_stats_neg = df_stats_neg.append({'filename':result[0][-13:-4], 'total_publications':result[1], 'total_negative_samples': result[3]},ignore_index=True)\n",
        "    df_stats_neut = df_stats_neut.append({'filename':result[0][-13:-4], 'total_publications':result[1], 'total_neutral_samples': result[4]},ignore_index=True)\n",
        "\n",
        "    df_apps_pos = df_apps_pos.append(result[5])\n",
        "    df_apps_neg = df_apps_neg.append(result[6])\n",
        "    df_apps_neut = df_apps_neut.append(result[7])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total publications in /content/drive/MyDrive/dataset_patent/2019/ipg190101.xml 7126\n",
            "total positive samples in  /content/drive/MyDrive/dataset_patent/2019/ipg190101.xml 162\n",
            "total publications in /content/drive/MyDrive/dataset_patent/2019/ipg190101.xml 7126\n",
            "total negative samples in  /content/drive/MyDrive/dataset_patent/2019/ipg190101.xml 257\n",
            "total publications in /content/drive/MyDrive/dataset_patent/2019/ipg190101.xml 7126\n",
            "total neutral samples in  /content/drive/MyDrive/dataset_patent/2019/ipg190101.xml 204\n",
            "(162, 4)\n",
            "------------\n",
            "(257, 4)\n",
            "------------\n",
            "(204, 4)\n",
            "------------\n",
            "total publications in /content/drive/MyDrive/dataset_patent/2019/ipg190212.xml 5689\n",
            "total positive samples in  /content/drive/MyDrive/dataset_patent/2019/ipg190212.xml 125\n",
            "total publications in /content/drive/MyDrive/dataset_patent/2019/ipg190212.xml 5689\n",
            "total negative samples in  /content/drive/MyDrive/dataset_patent/2019/ipg190212.xml 209\n",
            "total publications in /content/drive/MyDrive/dataset_patent/2019/ipg190212.xml 5689\n",
            "total neutral samples in  /content/drive/MyDrive/dataset_patent/2019/ipg190212.xml 146\n",
            "(125, 4)\n",
            "------------\n",
            "(209, 4)\n",
            "------------\n",
            "(146, 4)\n",
            "------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKqtYgnYFmax"
      },
      "source": [
        "df_stats_pos.to_csv(path+'/20'+result[0][-10:-8]+'_pos_stats.csv')\n",
        "df_stats_neg.to_csv(path+'/20'+result[0][-10:-8]+'_neg_stats.csv')\n",
        "df_stats_neut.to_csv(path+'/20'+result[0][-10:-8]+'_neut_stats.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILB-kKmMwDx1"
      },
      "source": [
        "df_apps_pos.to_csv(path+'/20'+result[0][-10:-8]+'_pos_apps.csv')\n",
        "df_apps_neg.to_csv(path+'/20'+result[0][-10:-8]+'_neg_apps.csv')\n",
        "df_apps_neut.to_csv(path+'/20'+result[0][-10:-8]+'_neut_apps.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzhXBS6gwost"
      },
      "source": [
        "finish  = datetime.now()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vGPLm1ewrsj",
        "outputId": "dd81b3ee-c0c5-42a4-fd18-11a7cf926896"
      },
      "source": [
        "print(finish-start)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:26:28.039698\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}